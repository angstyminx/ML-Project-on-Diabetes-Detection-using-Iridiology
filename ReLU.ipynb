{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angstyminx/ML-Project-on-Diabetes-Detection-using-Iridiology/blob/main/ReLU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/train.zip.001.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIbtiAo1B257",
        "outputId": "cc9b190b-cc57-445a-f188-77417a4d3784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train.zip.001.zip\n",
            "  inflating: train.zip.001           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download diabetic-retinopathy-detection \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbmFanv18g6R",
        "outputId": "baaa9f59-86d3-43d1-9dc7-1ecf2b16fad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.zip.001.zip to /content\n",
            "100% 7.81G/7.81G [02:32<00:00, 52.4MB/s]\n",
            "\n",
            "Downloading test.zip.002.zip to /content\n",
            "100% 7.81G/7.81G [02:04<00:00, 64.8MB/s]\n",
            "100% 7.81G/7.81G [02:04<00:00, 67.3MB/s]\n",
            "Downloading train.zip.002.zip to /content\n",
            "100% 7.81G/7.81G [02:26<00:00, 64.6MB/s]\n",
            "100% 7.81G/7.81G [02:26<00:00, 57.3MB/s]\n",
            "Downloading test.zip.006.zip to /content\n",
            "100% 7.81G/7.81G [01:49<00:00, 86.5MB/s]\n",
            "100% 7.81G/7.81G [01:49<00:00, 76.4MB/s]\n",
            "Downloading test.zip.005.zip to /content\n",
            "100% 7.81G/7.81G [02:36<00:00, 61.6MB/s]\n",
            "100% 7.81G/7.81G [02:36<00:00, 53.7MB/s]\n",
            "Downloading test.zip.001.zip to /content\n",
            "100% 7.81G/7.81G [03:13<00:00, 53.0MB/s]\n",
            "100% 7.81G/7.81G [03:13<00:00, 43.4MB/s]\n",
            "Downloading train.zip.005.zip to /content\n",
            "100% 1.33G/1.33G [00:26<00:00, 58.1MB/s]\n",
            "100% 1.33G/1.33G [00:26<00:00, 54.1MB/s]\n",
            "Downloading train.zip.004.zip to /content\n",
            "100% 7.81G/7.81G [02:10<00:00, 60.5MB/s]\n",
            "100% 7.81G/7.81G [02:10<00:00, 64.2MB/s]\n",
            "Downloading sample.zip to /content\n",
            " 87% 9.00M/10.4M [00:00<00:00, 45.2MB/s]\n",
            "100% 10.4M/10.4M [00:00<00:00, 49.3MB/s]\n",
            "Downloading sampleSubmission.csv.zip to /content\n",
            "  0% 0.00/81.6k [00:00<?, ?B/s]\n",
            "100% 81.6k/81.6k [00:00<00:00, 103MB/s]\n",
            "Downloading train.zip.003.zip to /content\n",
            "100% 7.81G/7.81G [02:48<00:00, 47.1MB/s]\n",
            "100% 7.81G/7.81G [02:48<00:00, 49.7MB/s]\n",
            "Downloading test.zip.007.zip to /content\n",
            "100% 2.75G/2.75G [01:00<00:00, 54.9MB/s]\n",
            "100% 2.75G/2.75G [01:00<00:00, 48.6MB/s]\n",
            "Downloading test.zip.004.zip to /content\n",
            "100% 7.81G/7.81G [01:58<00:00, 66.2MB/s]\n",
            "100% 7.81G/7.81G [01:59<00:00, 70.5MB/s]\n",
            "Downloading trainLabels.csv.zip to /content\n",
            "  0% 0.00/69.4k [00:00<?, ?B/s]\n",
            "100% 69.4k/69.4k [00:00<00:00, 56.4MB/s]\n",
            "Downloading test.zip.003.zip to /content\n",
            "100% 7.80G/7.81G [01:58<00:00, 66.5MB/s]\n",
            "100% 7.81G/7.81G [01:58<00:00, 70.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download diabetic-retinopathy-detection -f trainLabels.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcGkalLDWpC",
        "outputId": "ce903803-bd72-4a33-9fad-7ffc72778438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading trainLabels.csv.zip to /content\n",
            "\r  0% 0.00/69.4k [00:00<?, ?B/s]\n",
            "\r100% 69.4k/69.4k [00:00<00:00, 34.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1RTYqQSDmtA",
        "outputId": "65b6e75a-8e66-4c28-c086-f6be7b183dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/train.zip, /content/train.zip.zip or /content/train.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test.zip.001.zip\" -d \"/content/testset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C78ktPEdYOV9",
        "outputId": "84a6ca5d-4f3e-4f05-af96-433255dd3f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip.001.zip\n",
            "  inflating: /content/testset/test.zip.001  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test.zip.002.zip\" -d \"/content/testset\""
      ],
      "metadata": {
        "outputId": "261e7c5b-ebe6-489f-8903-a75d7b27b284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMy07X-VYwaM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip.002.zip\n",
            "  inflating: /content/testset/test.zip.002  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test.zip.003.zip\" -d \"/content/testset\""
      ],
      "metadata": {
        "outputId": "a699233d-2a64-4f57-a775-6269e886174a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FabKcxwGYzfw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip.003.zip\n",
            "  inflating: /content/testset/test.zip.003  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test.zip.004.zip\" -d \"/content/testset\""
      ],
      "metadata": {
        "outputId": "a73f5afe-ec8c-44ea-ec7e-8a09e98d6e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR2tBYB1Y08i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip.004.zip\n",
            "  inflating: /content/testset/test.zip.004  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test.zip.005.zip\" -d \"/content/testset\""
      ],
      "metadata": {
        "outputId": "29ca1ee8-da04-425e-e3b5-1134a129d54b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHtW04JjY16q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip.005.zip\n",
            "  inflating: /content/testset/test.zip.005  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test.zip.006.zip\" -d \"/content/testset\""
      ],
      "metadata": {
        "outputId": "d5e84608-90de-44ad-fc61-3a8f707861e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jvk3aqdY4yR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip.006.zip\n",
            "  inflating: /content/testset/test.zip.006  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/test.zip.007.zip\" -d \"/content/testset\""
      ],
      "metadata": {
        "outputId": "6843ca0e-4107-4984-b6c9-577be62f6be4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPvaJN-DY58r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip.007.zip\n",
            "  inflating: /content/testset/test.zip.007  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/testset/test.zip.001\" -d \"/content/testset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJQFr684awfq",
        "outputId": "c5196b88-cf9c-4bc6-8c0e-31a8e89db069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/testset/test.zip.001\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/testset/test.zip.001 or\n",
            "        /content/testset/test.zip.001.zip, and cannot find /content/testset/test.zip.001.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transform\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uDuFL6co_cr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "xei0beapAHCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ODC(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 13]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "VNphMO8JFtl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Retine(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "fG9MGhGeGA_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "import math"
      ],
      "metadata": {
        "id": "eW-yreHuBtqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class block(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
        "    ):\n",
        "        super(block, self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels * self.expansion,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Essentially the entire ResNet is in these 4 lines below\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    intermediate_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(intermediate_channels * 4),\n",
        "            )\n",
        "\n",
        "        layers.append(\n",
        "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = intermediate_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def ResNet50(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def ResNet101(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def ResNet152(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet101(img_channel=3, num_classes=1000)\n",
        "    dataset = Retine()\n",
        "    #y = net(torch.randn(4, 3, 224, 224)).to(\"cpu\")\n",
        "    #print(y.size())\n",
        "\n",
        "\n",
        "test()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK8QIUQFwiMl",
        "outputId": "e8ecd8e8-2f97-406e-cd1e-4b1a37cdc4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1000])\n"
          ]
        }
      ]
    }
  ]
}